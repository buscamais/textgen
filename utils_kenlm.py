"""
These codes are originally from ARAE utils.py
https://github.com/jakezhaojb/ARAE
Some parts are modified
"""
import os
def load_kenlm():
    global kenlm
    import kenlm

def train_ngram_lm(kenlm_path, data_path, output_path, N):
    """
    Trains a modified Kneser-Ney n-gram KenLM from a text file.
    Creates a .arpa file to store n-grams.
    """
    # create .arpa file of n-grams
    curdir = os.path.abspath(os.path.curdir)
    # discount_fallback is added to prevent error
    command = "bin/lmplz -o "+str(N)+" <"+os.path.join(curdir, data_path) + \
              " >"+os.path.join(curdir, output_path) + ' --discount_fallback'
    os.system("cd "+os.path.join(kenlm_path, 'build')+" && "+command)

    load_kenlm()
    # create language model
    statinfo = os.stat(output_path)
    if statinfo.st_size < 1:
        print('.arpa file size is 0 or too small')
        return None
    model = kenlm.Model(output_path)

    return model


def get_ppl(lm, sentences):
    """
    Assume sentences is a list of strings (space delimited sentences)
    """
    total_nll = 0
    total_wc = 0
    for sent in sentences:
        s = ' '.join(sent)
        words = s.strip().split()
        score = lm.score(s, bos=True, eos=False)
        word_count = len(words)
        total_wc += word_count
        total_nll += score
    ppl = 10**-(total_nll/total_wc)
    return ppl
